{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding an Observation Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# load data\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "# standardize features\n",
    "features_standardized = standardizer.fit_transform(features)\n",
    "\n",
    "# two nearest neighbors\n",
    "nearest_neighbors = NearestNeighbors(n_neighbors = 2, \n",
    "                                    metric = 'euclidean')\n",
    "nearest_neighbors.fit(features_standardized)\n",
    "\n",
    "# Create an observation\n",
    "new_observation = [ 1, 1, 1, 1]\n",
    "\n",
    "# predict \n",
    "distances, indices = nearest_neighbors.kneighbors([new_observation])\n",
    "\n",
    "# View distance to its nearest neighbors (vectors)\n",
    "features_standardized[indices]\n",
    "\n",
    "# view observation nearest neighbors (calculated)\n",
    "distances\n",
    "\n",
    "# list of nearest neighbors\n",
    "nearest_neighbors_with_self = nearest_neighbors.kneighbors_graph(\n",
    "    features_standardized).toarray()\n",
    "\n",
    "# metric: euclidean, manhattan, minkowski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating K-Nearest Neighbor Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0.6, 0.4],\n",
       "       [0. , 0. , 1. ]])"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import datasets\n",
    "\n",
    "# Load data\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# standardize features\n",
    "features_standardized = StandardScaler().fit_transform(features)\n",
    "\n",
    "# Train KNN\n",
    "knn = KNeighborsClassifier(n_neighbors = 5, n_jobs=-1,\n",
    "                           metric = 'manhattan')\n",
    "knn.fit(features_standardized, target)\n",
    "\n",
    "# Create two observations\n",
    "new_observations = [[ 0.75, 0.75, 0.75, 0.75],\n",
    " [ 1, 1, 1, 1]]\n",
    "\n",
    "# Predict the class of two observations\n",
    "knn.predict(new_observations)\n",
    "knn.predict_proba(new_observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifying the Best Neighborhood Size: the best value for K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load data\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# Standardize features\n",
    "features_standardized = standardizer.fit_transform(features)\n",
    "\n",
    "# create KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors =5, n_jobs =-1)\n",
    "\n",
    "# create pipeline\n",
    "pipeline = Pipeline([('standardizer', standardizer), ('knn', knn)])\n",
    "\n",
    "# Create space of candidate values\n",
    "search_space = [{\"knn__n_neighbors\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}]\n",
    "\n",
    "# Create grid search\n",
    "classifier = GridSearchCV(\n",
    " pipeline, search_space, cv=5, verbose=0).fit(\n",
    "    features_standardized, target)\n",
    "\n",
    "# Best neighborhood size (k)\n",
    "classifier.best_estimator_.get_params()[\"knn__n_neighbors\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Radius-Based Nearest Neighbor Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# load data\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "targets = iris.target\n",
    "\n",
    "# standardize features\n",
    "features_standardized = StandardScaler().fit_transform(features)\n",
    "\n",
    "# create radius based nn\n",
    "radius_nn = RadiusNeighborsClassifier(radius = .5, n_jobs=-1)\n",
    "radius_nn.fit(features_standardized, target)\n",
    "\n",
    "# generate new observations\n",
    "new_obs = [[1,1,1,1]]\n",
    "\n",
    "# predict new observation class\n",
    "radius_nn.predict(new_obs)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
