{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Binary Classifier : only two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17738424, 0.82261576]])"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# load data\n",
    "iris = load_iris()\n",
    "features = iris.data [:100, :]\n",
    "targets = iris.target [:100]\n",
    "\n",
    "# standardize features\n",
    "features_standardized = StandardScaler().fit_transform(features)\n",
    "\n",
    "# create logistic reg\n",
    "logistic_reg = LogisticRegression(random_state = 420). \\\n",
    "    fit(features_standardized, targets)\n",
    "\n",
    "# Create new observation\n",
    "new_observation = [[.5, .5, .5, .5]]\n",
    "\n",
    "# predict values\n",
    "logistic_reg.predict(new_observation)  \n",
    "logistic_reg.predict_proba(new_observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Multiclass Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0387617 , 0.40669108, 0.55454723]])"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# load data\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "targets = iris.target\n",
    "\n",
    "# standardize features\n",
    "features_standardized = StandardScaler().fit_transform(features)\n",
    "\n",
    "# create logistic reg\n",
    "logistic_reg = LogisticRegression(random_state = 420, \n",
    "                                 multi_class = 'ovr'). \\\n",
    "    fit(features_standardized, targets)\n",
    "\n",
    "# Create new observation\n",
    "new_observation = [[.5, .5, .5, .5]]\n",
    "\n",
    "# predict values\n",
    "logistic_reg.predict(new_observation)  \n",
    "logistic_reg.predict_proba(new_observation)\n",
    "\n",
    "# with multiclass logisitc regression, we add the parameter\n",
    "# multi_class = 'ovr' : one-vs-rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reducing Variance Through Regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# load data\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "targets = iris.target\n",
    "\n",
    "# standardize features\n",
    "features_standardized = StandardScaler().fit_transform(features)\n",
    "\n",
    "# Create logistic regression with regularization parameter\n",
    "logistic_reg = LogisticRegressionCV(penalty='l2', Cs = 10, \n",
    "                                   random_state = 0, n_jobs =-1)\n",
    "logistic_reg.fit(features_standardized, targets)\n",
    "\n",
    "# We add a regularition parmater: l1 or l2 with a hyperparameter\n",
    "# of its own:Cs. There is no way to optimize the Cs parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Classifier a Very Large Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='ovr', n_jobs=None, penalty='l2',\n",
       "                   random_state=420, solver='sag', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# load data\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "targets = iris.target\n",
    "\n",
    "# standardize features\n",
    "features_standardized = StandardScaler().fit_transform(features)\n",
    "\n",
    "# create logistic regression\n",
    "logistic_regression = LogisticRegression(random_state = 420,\n",
    "                                        solver = 'sag', \n",
    "                                        multi_class = 'ovr')\n",
    "logistic_regression.fit(features_standardized, targets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Imbalanced Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# load data \n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# Make class highly imbalanced by removing first 40 observations\n",
    "features = features[40:,:]\n",
    "target = target[40:]\n",
    "\n",
    "# create target vector for each class\n",
    "target = np.where((target == 0), 0, 1)\n",
    "\n",
    "# standardize features\n",
    "features_standardized = StandardScaler().fit_transform(features)\n",
    "\n",
    "# Create Logistic Regression\n",
    "logistic_regression = LogisticRegression(random_state = 0, \n",
    "                                        class_weight = 'balanced')\n",
    "logistic_regression.fit(features_standardized, target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
