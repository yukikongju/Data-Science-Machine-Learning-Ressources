{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Numerical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Scaling Numerical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rescaling a Numerical feature between 0,1 with MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.28571429],\n",
       "       [0.35714286],\n",
       "       [0.42857143],\n",
       "       [1.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "feature = np.array([[-500.5],\n",
    " [-100.1],\n",
    " [0],\n",
    " [100.1],\n",
    " [900.9]])\n",
    "\n",
    "# creater scaler\n",
    "minmax_scale = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "# scaled feature\n",
    "scaled_feature = minmax_scale.fit_transform(feature)\n",
    "\n",
    "scaled_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardizing feature using mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  4.4408920985006264e-17\n",
      "Standard deviation:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "x = np.array([[-1000.1],\n",
    " [-200.2],\n",
    " [500.5],\n",
    " [600.6],\n",
    " [9000.9]])\n",
    "\n",
    "# create scaler\n",
    "scaler = StandardScaler() # classical standardizer\n",
    "robust_scaler = RobustScaler() # if features has outliers\n",
    "\n",
    "# transform features\n",
    "standardized_features = scaler.fit_transform(x)\n",
    "\n",
    "standardized_features\n",
    "\n",
    "print('Mean: ', standardized_features.mean())\n",
    "print('Standard deviation: ', standardized_features.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing Observations with unit vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.5       ],\n",
       "       [0.24444444, 0.75555556],\n",
       "       [0.06912442, 0.93087558],\n",
       "       [0.04524008, 0.95475992],\n",
       "       [0.76760563, 0.23239437]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# create matrix\n",
    "features = np.array([[0.5, 0.5],\n",
    " [1.1, 3.4],\n",
    " [1.5, 20.2],\n",
    " [1.63, 34.4],\n",
    " [10.9, 3.3]])\n",
    "\n",
    "# create normalizer\n",
    "normalizer = Normalizer()\n",
    "\n",
    "# Normalize data\n",
    "features_normalized = normalizer.fit_transform(features)\n",
    "features_normalized\n",
    "\n",
    "# alternative: using euclidean norm (l2): sum squared\n",
    "features_l2_norm = Normalizer(norm='l2').transform(features)\n",
    "features_l2_norm\n",
    "\n",
    "# alternative: using manhattan norm (l1): absolute value\n",
    "features_l1_norm = Normalizer(norm='l1').transform(features)\n",
    "features_l1_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating polynomial and interaction features:  non linear relationship between features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 3., 6.],\n",
       "       [2., 3., 6.],\n",
       "       [2., 3., 6.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Create feature matrix\n",
    "features = np.array([[2, 3],\n",
    " [2, 3],\n",
    " [2, 3]])\n",
    "\n",
    "# create polynomial features object\n",
    "polynomial_interaction = PolynomialFeatures(degree = 2,\n",
    "            include_bias = False,\n",
    "            interaction_only = True)\n",
    "\n",
    "# create polynomial features\n",
    "polynomial_interaction.fit_transform(features)\n",
    "\n",
    "# degree: maximum degreee of polynomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feat_1  feat_2\n",
       "0      12      13\n",
       "1      12      13\n",
       "2      12      13"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import pandas as pd\n",
    "\n",
    "# Create feature matrix\n",
    "features = np.array([[2, 3],\n",
    " [2, 3],\n",
    " [2, 3]])\n",
    "\n",
    "# define function\n",
    "def add_ten(x):\n",
    "    return x+10\n",
    "\n",
    "# create tranformer\n",
    "ten_transformer = FunctionTransformer(add_ten)\n",
    "\n",
    "# tranform features\n",
    "ten_transformer.fit_transform(features)\n",
    "\n",
    "# alternative: use the apply function\n",
    "df = pd.DataFrame(features, columns = ['feat_1', 'feat_2'])\n",
    "df.apply(add_ten)\n",
    "\n",
    "# note: we use transformer mainly to transform values into log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Break up  Features into bins ie Discretizating Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binarize features according to treshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "# Create feature\n",
    "age = np.array([[6],\n",
    " [12],\n",
    " [20],\n",
    " [36],\n",
    " [65]])\n",
    "\n",
    "# create binarizer: split data in two\n",
    "binarizer = Binarizer(25)\n",
    "\n",
    "# transform features\n",
    "binarizer.fit_transform(age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Data into multiple bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [3]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.digitize(age, bins=[20,30,64], right = True)\n",
    "\n",
    "# right = True makes treshold inclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
